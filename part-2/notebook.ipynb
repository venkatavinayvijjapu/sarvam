{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: huggingface_hub in c:\\users\\abc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (0.22.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\abc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from huggingface_hub) (3.14.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\abc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from huggingface_hub) (2024.5.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\abc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from huggingface_hub) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\abc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from huggingface_hub) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\abc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from huggingface_hub) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\abc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from huggingface_hub) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\abc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from huggingface_hub) (4.12.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\abc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tqdm>=4.42.1->huggingface_hub) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\abc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests->huggingface_hub) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\abc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests->huggingface_hub) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\abc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests->huggingface_hub) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\abc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests->huggingface_hub) (2024.6.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "import streamlit as st\n",
    "from PyPDF2 import PdfReader\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "import json\n",
    "# from langchain_community.embeddings import SentenceTransformerEmbeddings\n",
    "\n",
    "# PDFQuestionAnswering class\n",
    "class PDFQuestionAnswering(BaseModel):\n",
    "    name: str = \"PDF Question Answering\"\n",
    "    description: str = \"Useful for retrieving relevant information from a PDF based on a query.\"\n",
    "\n",
    "    def process_pdf(self, uploaded_file):\n",
    "        pdfreader = PdfReader(uploaded_file)\n",
    "        raw_text = ''\n",
    "        for page in pdfreader.pages:\n",
    "            content = page.extract_text()\n",
    "            if content:\n",
    "                raw_text += content\n",
    "        return raw_text\n",
    "\n",
    "    def split_text(self, raw_text: str):\n",
    "        text_splitter = CharacterTextSplitter(\n",
    "            separator=\"\\n\",\n",
    "            chunk_size=800,\n",
    "            chunk_overlap=200,\n",
    "            length_function=len,\n",
    "        )\n",
    "        return text_splitter.split_text(raw_text)\n",
    "\n",
    "    def get_relevant_chunks(self, texts, query: str):\n",
    "        # Generate embeddings for the texts\n",
    "        # embeddings = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "        openai_api_key=OPENAI_API_KEY =<OPENAI_API_KEY>\n",
    "        embeddings = OpenAIEmbeddings()  # Replace this with another embedding model if needed\n",
    "        \n",
    "        # Create a vector database (e.g., FAISS)\n",
    "        document_search = FAISS.from_texts(texts, embeddings)\n",
    "\n",
    "        # Perform a similarity search to find the most relevant chunks\n",
    "        docs = document_search.similarity_search(query)\n",
    "        return [doc.page_content for doc in docs]\n",
    "\n",
    "    def run(self, query: str):\n",
    "        uploaded_file='handbook.pdf'\n",
    "        if uploaded_file is not None and query:\n",
    "            # Process the PDF file\n",
    "            raw_text = self.process_pdf(uploaded_file)\n",
    "\n",
    "            # Split the text into chunks\n",
    "            texts = self.split_text(raw_text)\n",
    "\n",
    "            # Retrieve relevant chunks based on the query\n",
    "            relevant_chunks = self.get_relevant_chunks(texts, query)\n",
    "            \n",
    "            # Return the relevant chunks\n",
    "            return relevant_chunks\n",
    "        else:\n",
    "            return {\"error\": \"PDF file or query not provided\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_community import GoogleSearchAPIWrapper\n",
    "from langchain_core.tools import Tool\n",
    "from langchain.tools.base import StructuredTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_search = GoogleSearchAPIWrapper()\n",
    "google_tool = Tool(\n",
    "    name=\"google-search\",\n",
    "    description=\"Search Google for recent results.\",\n",
    "    func=google_search.run\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] =<OPENAIKEY>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Messages added successfully\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "file_path = './handbook.pdf'\n",
    "\n",
    "with open(file_path, 'rb') as file:\n",
    "    response = requests.post(f\"http://127.0.0.1:8000/add_pdf/\", files={\"file\": file})\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(\"Messages added successfully\")\n",
    "else:\n",
    "    print(f\"Failed to add messages. Status code: {response.status_code}\")\n",
    "    print(\"Response content:\", response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Messages added successfully\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "url='https://blog.futuresmart.ai/guide-to-langsmith'\n",
    "# file_path = './handbook.pdf'\n",
    "\n",
    "# with open(file_path, 'rb') as file:\n",
    "response = requests.post(f\"http://127.0.0.1:8000/scrape_webdata/\", json={\"url\": url})\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(\"Messages added successfully\")\n",
    "else:\n",
    "    print(f\"Failed to add messages. Status code: {response.status_code}\")\n",
    "    print(\"Response content:\", response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "import requests\n",
    "from pydantic_models import QueryRequest\n",
    "\n",
    "class PDFQuestionAnswering(BaseModel):\n",
    "    name: str = \"Pdf Question Answering\"\n",
    "    description: str = \"Useful for getting relavent information from pdf\"\n",
    "\n",
    "    def run(self, query: str) -> str:\n",
    "        try:\n",
    "            print(query)\n",
    "            request_data=QueryRequest(input=query)\n",
    "            response = requests.post(f\"http://127.0.0.1:8000/search_query_in_pdf\", json=request_data.dict())\n",
    "            response.raise_for_status()\n",
    "            return response.json()\n",
    "        except requests.RequestException as e:\n",
    "            # Handle request errors\n",
    "            return {\"error\": f\"Request failed: {str(e)}\"}\n",
    "        except Exception as e:\n",
    "            # Handle other exceptions\n",
    "            return {\"error\": str(e)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "import requests\n",
    "from pydantic_models import QueryRequest\n",
    "\n",
    "class WebQuestionAnswering(BaseModel):\n",
    "    name: str = \"Web Question Answering\"\n",
    "    description: str = \"Useful to Answer user based on query from webdata.\"\n",
    "\n",
    "    def run(self, query: str) -> str:\n",
    "        try:\n",
    "            print(query)\n",
    "            request_data=QueryRequest(input=query)\n",
    "            response = requests.post(f\"http://127.0.0.1:8000/search_query_in_web\", json=request_data.dict())\n",
    "            response.raise_for_status()\n",
    "            return response.json()\n",
    "        except requests.RequestException as e:\n",
    "            # Handle request errors\n",
    "            return {\"error\": f\"Request failed: {str(e)}\"}\n",
    "        except Exception as e:\n",
    "            # Handle other exceptions\n",
    "            return {\"error\": str(e)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'PDFQuestionAnswering' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m pdf_search \u001b[38;5;241m=\u001b[39m \u001b[43mPDFQuestionAnswering\u001b[49m()\n\u001b[0;32m      2\u001b[0m pdf_tool \u001b[38;5;241m=\u001b[39m StructuredTool\u001b[38;5;241m.\u001b[39mfrom_function(\n\u001b[0;32m      3\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpdf-search\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      4\u001b[0m     description\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSearch Pdf for relavent information\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      5\u001b[0m     func\u001b[38;5;241m=\u001b[39mpdf_search\u001b[38;5;241m.\u001b[39mrun\n\u001b[0;32m      6\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'PDFQuestionAnswering' is not defined"
     ]
    }
   ],
   "source": [
    "pdf_search = PDFQuestionAnswering()\n",
    "pdf_tool = StructuredTool.from_function(\n",
    "    name=\"pdf-search\",\n",
    "    description=\"Search Pdf for relavent information\",\n",
    "    func=pdf_search.run\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "GOOGLE_API_KEY=<GOOGLE_API_KEY>\n",
    "GOOGLE_CSE_ID=<GOGGLE_CSE_ID>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1 Child\\'s First Name. (Type or print). BARACK. CERTIFICATE OF LIVE BIRTH lb ... OBAMA, II. Day. 4. 6b. Island. Year. 5b. Hour. 1961 7:24 P.M.. Oahu. 6d. Is Place\\xa0... As a member of the Democratic Party, he was the first African-American president in U.S. history. Obama previously served as a U.S. senator representing\\xa0... Apr 7, 2021 ... ... WHAT IVE BEEN SAYING. Reply reply. u/MarkXD69therickroll avatar ... Morons, Obama IS his last name, and his first name is President. Apr 12, 2017 ... Barack hussein Obama was actually born in alkita, Afghanistan he is a Muslim. He is not African American. His birth certificate was altered by\\xa0... Barack Hussein Obama II was born August 4, 1961, in Honolulu, Hawaii, to parents Barack H. Obama, Sr., and Stanley Ann Dunham. A museum that asks you to believe—not just in President Obama\\'s power to create change, but in your own. ... (All fields required.) First name. First name. Last\\xa0... Michelle Robinson Obama was born in DeYoung, Illinois, on January 17, 1964, to parents Frasier Robinson III and Marian Shields. Jun 22, 2020 ... His first name is Obama, last name is care. Common misconception that Obama is actually Obama\\'s last name. The Middle East remained a key foreign policy challenge. ... Learn more about Barack Obama\\'s spouse, Michelle Obama. President Barack Obama and First Lady\\xa0... Mar 22, 2008 ... Keith didn\\'t know at first that Obama\\'s given name was Barack. \"We ... \"What kind of name is Barry Obama—for a brother?\" Moore asked\\xa0...'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "google_search.run(\"What's Obama's first name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "web_search = WebQuestionAnswering()\n",
    "web_tool = Tool(\n",
    "    name=\"Web-search\",\n",
    "    description=\"Search Web data for information\",\n",
    "    func=web_search.run\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the name of the company?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Closing Statement\\nThank you for reading our handbook. We hope it has provided you with an understanding of our mission, history, and\\nstructure as well as our current policies and guidelines. We look forward to working with you to create a successful\\nCompany and a safe, productive, and pleasant workplace.\\nShruti Gupta, CEO\\nZania, Inc.\\n45 Zania, Inc.\\nZania Employee Handbook\\nSeptember 07, 2023 This policy may not be appropriate in its entirety for employees working in Montana.\\n2.0 \\nIntroductory Language and Policies\\n2.1 \\nAbout the Company\\n[[Add your about the company statement here.]]\\n2.2 \\nCompany Facilities\\n[[Insert information about your company facilities here.]]\\n2.3 \\nEthics Code\\nZania, Inc. will conduct business honestly and ethically wherever operations are maintained. We strive to improve the quality\\nof our services, products, and operations and will maintain a reputation for honesty, fairness, respect, responsibility,\\nintegrity, trust, and sound business judgment. Our managers and employees are expected to adhere to high standards of\\nbusiness and personal integrity as a representation of our business practices, at all times consistent with their duty of loyalty\\nto the Company.\\nWe expect that officers, directors, and employees will not knowingly misrepresent the Company and will not speak on behalf\\nof the Company unless specifically authorized. The confidentiality of trade secrets, proprietary information, and similar\\nconfidential commercially-sensitive information (i.e. financial or sales records/reports, marketing or business\\nstrategies/plans, product development, customer lists, patents, trademarks, etc.) about the Company or operations, or that of\\nour customers or partners, is to be treated with discretion and only disseminated on a need-to-know basis (see policies\\nrelating to privacy).\\nViolation of the Code of Ethics can result in discipline, up to and including termination of employment. The degree of\\ndiscipline imposed may be influenced by the existence of voluntary disclosure of any ethical violation and whether or not the\\nviolator cooperated in any subsequent investigation.\\n2.4 \\nMission Statement\\n[[Insert your company\\'s mission statement here.]]\\n2.5 \\nOur Organization\\n[[Add information about your organization or organizational chart here.]]\\n2.6 \\nRevisions to Handbook\\nThis handbook is our attempt to keep you informed of the terms and conditions of your employment, including Zania, Inc.\\npolicies and procedures. The handbook is not a contract. The Company reserves the right to revise, add, or delete from this\\nhandbook as we determine to be in our best interest, except the policy concerning at-will employment. When changes are\\nmade to the policies and guidelines contained herein, we will endeavor to communicate them in a timely fashion, typically in\\na written supplement to the handbook or in a posting on company bulletin boards.\\n3.0 \\nHiring and Orientation Policies\\n3.1 \\nAccommodations for Pregnant Employees\\nZania, Inc. will provide reasonable accommodation to pregnant employees for known limitations related to pregnancy,\\nchildbirth, or other related medical conditions in accordance with the federal Pregnant Workers Fairness Act (PWFA).\\n5 Software programs purchased and provided by Zania, Inc. are to be used only for creating, researching, and processing\\nmaterials for Company use. By using Company hardware, software, and networking systems you assume personal\\nresponsibility for their use and agree to comply with this policy and other applicable Company policies, as well as city, state,\\nand federal laws and regulations.\\nAll software acquired for or on behalf of the Company, or developed by Company employees or contract personnel on behalf\\nof the Company, is and will be deemed Company property. It is the policy of the Company to respect all computer software\\nrights and to adhere to the terms of all software licenses to which the Company is a party. The [[Director of Information\\nSystems]] is responsible for enforcing these guidelines.\\nYou may not illegally duplicate any licensed software or related documentation. Unauthorized duplication of software may\\nsubject you and/or the Company to both civil and criminal penalties under the United States Copyright Act. To purchase\\nsoftware, obtain your manager\\'s approval. All software acquired by the Company must be purchased through [[Information\\nSystems or appropriate department]].\\nYou may not duplicate, copy, or give software to any outsiders including clients, contractors, customers, and others. You\\nmay use software on local area networks or on multiple machines only in accordance with applicable license agreements\\nentered into by the Company.\\n6.2 \\nEmployer Sponsored Social Events\\nZania, Inc. holds periodic social events for employees. Be advised that your attendance at these events is voluntary and\\ndoes not constitute part of your work-related duties. Any exceptions to this policy must be in writing and signed by a\\nManager prior to the event.\\nAlcoholic beverages may be available at these events. If you choose to drink alcoholic beverages, you must do so in a\\nresponsible manner. Do not drink and drive. Instead, please call a taxi or appoint a designated driver.\\n6.3 \\nEmployer-Provided Cell Phones/Mobile Devices\\nZania, Inc. may issue certain employees a Company cell phone/mobile device for work-related communications and/or\\noperations. If you drive a vehicle during your employment, you may not use any cell phone/mobile device or other\\ncommunication device while driving unless the device is equipped or configured with a \"hands-free\" listening/speaking\\noption, and you in fact utilize the hands-free device. \\n[[We understand that you may use the cell phone/mobile device for personal use; however, such personal use should not\\nexceed the plan allowance. When the cell phone/mobile device is used for personal reasons and the activity results in\\nadditional cost to the Company, you are responsible for the cost of that usage, including all applicable taxes unless\\nprohibited by law.]]\\nThe Company owns and remains entitled to all cell phone/mobile devices issued to employees, including all passwords\\ncontrolling access to them.\\nYou may not change those passwords except with permission. At the time of employment termination, all such equipment\\nand passwords must be returned to the Company in operable condition.\\nViolation of this policy may result in discipline, up to and including termination of employment.\\n6.4 \\nNonsolicitation/Nondistribution Policy\\nTo avoid disruption of business operations or disturbance of employees, visitors, and others, Zania, Inc. has implemented a\\nNonsolicitation/Nondistribution Policy. For purposes of this policy, \"solicitation\" includes, but is not limited to, selling items or\\nservices, requesting contributions, and soliciting or seeking to obtain membership in or support for any organization.\\nSolicitation performed through verbal, written, or electronic means is covered by the Nonsolicitation/Nondistribution Policy.\\n15 '"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_search.run(\"What is the name of the company?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is meant by langsmith?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Guide to langsmithFutureSmart AI BlogFollowFutureSmart AI BlogFollowGuide to langsmithVenkata Vinay Vijjapu·Jun 7, 2024·7 min readTable of contentsIntroductionInstallationPython:Type Script:Setting Up Your EnvironmentSample ProjectUse CasesConclusionResources and Further ReadingIntroduction\\nLarge language models (LLMs) are the talk of the town, with their potential applications seemingly limitless. But for developers, translating LLM potential into real-world applications can be a bumpy ride. Debugging complex workflows, ensuring reliability, and maintaining smooth operation are just a few hurdles on the path to production.\\nIntroducing LangSmith, your one-stop shop for building and deploying robust LLM applications. LangSmith is a comprehensive DevOps platform designed to streamline the entire LLM development process, from initial concept to real-world impact.\\nWith LangSmith, you can:\\n\\nCraft LLMs with Confidence: Develop applications intuitively with a user-friendly interface that simplifies even intricate workflows.\\n\\nTest Like a Pro: Uncover and fix vulnerabilities before deployment with LangSmith\\'s robust testing suite.\\n\\nGain Deep Insights: Evaluate your application\\'s performance with LangSmith\\'s in-depth tools, ensuring optimal functionality.\\n\\nMonitor with Peace of Mind: Maintain application stability with LangSmith\\'s real-time monitoring features.\\n\\n\\nBut LangSmith goes beyond just development. It equips you with the power to delve into your LLM application\\'s inner workings. This allows you to:\\n\\nDebug with Precision: Troubleshoot complex issues efficiently with LangSmith\\'s debugging tools.\\n\\nFine-tune Performance: Optimize your application\\'s functionality for maximum impact.\\n\\n\\nWhether you\\'re a seasoned developer pushing the boundaries of LLMs or just starting your journey, LangSmith empowers you to unlock the full potential of these powerful tools.\\nInstallation\\nPython:\\n\\nOpen a terminal or command prompt.\\n\\nType the following command and press Enter:\\n\\n\\npip install -U langsmith\\n\\nThis downloads and installs the Langsmith library for Python.\\nType Script:\\n\\nOpen a terminal or command prompt and navigate to your project directory.\\n\\nType the following command and press Enter:\\n\\n\\nyarn add langchain langsmith\\n\\nThis installs the necessary packages using yarn. If you prefer npm, use npm install langchain langsmith instead.\\nSetting Up Your Environment\\nCreate an API Key:\\n\\nHead to the Langsmith website (Link)\\n\\n\\n  Go to your Settings page in the website.\\n\\nRegister if you\\'re new or sign in if you already have an account.\\n\\nClick on Create API Key and copy the generated API key.\\n \\n\\n\\nSet Environment Variables:\\n\\nOpen your terminal or command prompt.\\n\\nFor both Python and TypeScript:\\n\\nSet the LANGCHAIN_TRACING_V2 environment variable to true:\\n\\nSet the LANGCHAIN_API_KEY environment variable to your copied API key:\\n  export LANGCHAIN_TRACING_V2=true\\n  export LANGCHAIN_API_KEY=<your_api_key>\\n\\n\\n\\n\\n\\nSample Project\\n# Importing neccessary modules\\nimport streamlit as st\\nfrom langchain_openai import ChatOpenAI\\nfrom langchain_core.prompts import ChatPromptTemplate\\nfrom langchain_core.output_parsers import StrOutputParser\\nimport os\\nfrom dotenv import load_dotenv\\n\\n\\nstreamlit: This lets you build a cool website where people can interact with a chatbot.\\n\\nlangchain_openai: This helps you talk to a special program from OpenAI that can chat like a person.\\n\\nChatPromptTemplate & StrOutputParser (might be custom): These sound like special tools you made (or got from somewhere) to help control what you say to the chatbot and how it responds.\\n\\nos: This helps your program work with your computer\\'s files and folders.\\n\\ndotenv: This keeps your secret codes (like passwords) safe by hiding them in a separate file.\\n\\n\\n# Load environment variables from .env file\\nload_dotenv()\\n\\nos.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\\nos.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\\nos.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\") Token Count: The number of tokens processed at each stage.\\n\\nExecution Time: The time taken for each sub-process to complete.\\n\\n\\nTargeted Testing and Debugging: By analyzing the chain and its individual components, you can pinpoint potential issues within your LLM\\'s reasoning or response generation. LangSmith empowers you to focus your debugging efforts on specific areas, streamlining the process.\\nUse Cases\\n1. Optimizing LLM Performance:\\nImagine you\\'re developing a chatbot powered by an LLM. The chatbot sometimes provides clunky or irrelevant responses. LangSmith lets you examine the processing chain behind each response. You can see which steps take the most time or tokens, indicating areas for improvement. By analyzing these bottlenecks, you can refine prompts or fine-tune the LLM for better chatbot performance.\\n2. Identifying Biases:\\nLet\\'s say you\\'re concerned about potential biases in your LLM\\'s outputs. LangSmith allows you to track the sentiment of user queries and the corresponding LLM responses. This can reveal if the LLM is biased towards certain viewpoints or phrasings. You can then adjust training data or prompts to mitigate these biases.\\n3. Debugging LLM Reasoning:\\nYou\\'ve trained an LLM to do question answering, but it sometimes provides incorrect or nonsensical answers. LangSmith\\'s chain visualization helps you understand the LLM\\'s reasoning process for each answer. By examining which steps led to the wrong answer, you can identify flaws in the LLM\\'s logic or training data and address them.\\n4. Building Self-Improving LLMs:\\nLangSmith can be used to create LLMs that learn and improve over time. You can integrate user feedback with LangSmith. Positive feedback on LLM outputs can be used to automatically generate training datasets for further fine-tuning. Conversely, negative feedback can be used to identify areas needing improvement and target them for retraining.\\nConclusion\\nLangSmith is a platform designed to streamline the development, deployment, and monitoring of applications built around large language models (LLMs). By providing tools for debugging, testing, evaluation, and usage metrics, LangSmith aims to bridge the gap between LLM prototypes and production-grade applications. It offers benefits for both individual developers and organizations working with LLMs.\\nResources and Further Reading\\nFor additional information and resources on langsmith and langsmith-langchain, check out the following:\\nLangsmith\\nLangsmith-Langchain\\n\\nWanna look at the code: Github Link\\nlangsmithlangchaingenailarge language modelsllm\\xa0Share this os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\\nos.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\\nos.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")\\n\\n\\nopenai_api_key: This key unlocks access to OpenAI\\'s GPT models, empowering you to leverage their capabilities in your application.\\n\\nlangchain_tracing_v2: Setting this to \"true\" enables tracing within your Langchain account, allowing you to visualize the execution flow and identify potential issues.\\n\\nlangchain_api_key: This key serves as your Langchain API key, likely used for authentication purposes when interacting with Langchain\\'s services\\n\\n\\n# Define the prompt template\\nprompt = ChatPromptTemplate.from_messages(\\n    [\\n        (\"system\", \"You are my blog genertor. You are required to create a blog on that topic{question}\"),\\n        (\"user\", \"Question:{question}\")\\n    ]\\n)\\n\\n\\nA prompt, in the context of interacting with large language models like GPT, is a piece of text that instructs the model on what kind of response to generate. It sets the stage for the conversation and provides context for the user\\'s input\\n\\n# Initialize the model and output parser\\nmodel = ChatOpenAI(model=\"gpt-3.5-turbo\")\\noutput_parser = StrOutputParser()\\n\\n# Chain the prompt, model, and output parser\\nchain = prompt | model | output_parser\\n\\n\\nSetting Up the Chatbot Engine (model): We\\'re creating a connection to a powerful language model called GPT-3.5-turbo. Think of it as the brain of the chatbot, responsible for generating responses.\\n\\nCleaning Up the Response (output_parser): Sometimes the model\\'s response might be raw text. This line creates a tool to potentially make the response look better for the user.\\n\\nConnecting the Pieces (chain): This line simply joins the prompt (what you tell the chatbot), the model (the GPT-3 brain), and the cleanup tool into one smooth process.\\n\\n\\n# Streamlit interface\\nst.title(\"LangChain OpenAI Streamlit App\")\\n\\nquestion = st.text_input(\"Enter your topic:\")\\n\\nif st.button(\"Generate blog...\"):\\n    if not question:\\n        st.write(\"Please provide your topic.\")\\n    else:\\n        result = chain.invoke({\"question\": question})\\n        st.write(\"Blog:\")\\n        st.write(result)\\n\\n\\nThis is the interface code where a text box and a button are present. When a question is entered and the button is clicked, the system will process the question and initiate a response from GPT.\\n\\nTo see the code you can go with the link below.\\n\\n\\nTesting and Debugging Large Language Models with LangSmith:\\nThis document outlines a streamlined approach for testing and debugging Large Language Models (LLMs) using LangSmith, a dedicated platform designed to facilitate this process.\\n\\nAccess LangSmith: Navigate to the LangSmith website and log in to your account.\\n\\nLangmsith Link\\n\\nSelect Project: Within the LangSmith interface, locate and open the project containing the LLM you wish to test and debug.\\n \\n\\nReview Past Interactions: LangSmith will display a record of previous queries posed to your LLM.\\n \\n\\nVisualize Execution Chain: Upon selecting a specific query, LangSmith will present a visual representation of the internal processing steps (chain) your LLM undertook to generate the response.\\n \\n\\nDeep Dive into Sub-processes: Each step within the chain is readily accessible for examination. You can analyze:\\n\\n\\n\\nToken Count: The number of tokens processed at each stage.\\n\\nExecution Time: The time taken for each sub-process to complete. '"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "web_search.run(\"What is meant by langsmith?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import HuggingFaceEndpoint\n",
    "from langchain_community.chat_models.huggingface import ChatHuggingFace\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "HUGGINGFACEHUB_API_TOKEN='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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY =OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0, api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_structured_chat_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "prompt = hub.pull(\"hwchase17/openai-tools-agent\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], optional_variables=['chat_history'], input_types={'chat_history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]], 'agent_scratchpad': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, partial_variables={'chat_history': []}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'openai-tools-agent', 'lc_hub_commit_hash': 'c18672812789a3b9697656dd539edf0120285dcae36396d0b548ae42a4ed66f5'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant')), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')), MessagesPlaceholder(variable_name='agent_scratchpad')])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_openai_tools_agent\n",
    "agent = create_openai_tools_agent(llm, [google_tool,pdf_tool,web_tool], prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor=AgentExecutor(agent=agent, tools=[google_tool,pdf_tool,web_tool], verbose=True, handle_parsing_errors=True, max_iterations=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor.invoke({\"input\":\"name of company?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
